# ğŸ” Agente Daktus QA

> Sistema de validaÃ§Ã£o e correÃ§Ã£o automatizada de protocolos clÃ­nicos usando IA

**VersÃ£o Atual**: 2.3-production âœ…  
**PrÃ³xima VersÃ£o**: 3.0-alpha (em desenvolvimento)  
**Status**: Pronto para ProduÃ§Ã£o (v2) | Roadmap v3 Definido  
**Ãšltima AtualizaÃ§Ã£o**: 2025-11-30

---

## ğŸ¯ O Que Faz

### VersÃ£o 2.x (Atual - ProduÃ§Ã£o)

Valida protocolos clÃ­nicos (JSON) contra playbooks mÃ©dicos (texto/PDF) para garantir:

- âœ… ConsistÃªncia da lÃ³gica clÃ­nica
- âœ… Cobertura completa de sintomas
- âœ… Caminhos diagnÃ³sticos apropriados
- âœ… RecomendaÃ§Ãµes baseadas em evidÃªncias
- âœ… IdentificaÃ§Ã£o de gaps e oportunidades de melhoria

**Entrada**: Protocolo clÃ­nico (JSON) + Playbook mÃ©dico (Markdown/PDF)  
**SaÃ­da**: RelatÃ³rio de validaÃ§Ã£o clÃ­nica (texto + JSON) com anÃ¡lise de gaps e sugestÃµes de melhoria priorizadas

### VersÃ£o 3.0 (Em Desenvolvimento)

**EvoluÃ§Ã£o transformacional:** De auditoria passiva para correÃ§Ã£o ativa.

- âœ… Tudo da v2.x
- ğŸ”¥ **Auto-Apply de Melhorias** - Aplica correÃ§Ãµes automaticamente no JSON
- ğŸ”¥ **Chunking Inteligente** - Processa playbooks gigantes (50-200+ pÃ¡ginas)
- ğŸ”¥ **PriorizaÃ§Ã£o por Impacto** - SugestÃµes ranqueadas por ROI clÃ­nico-financeiro
- ğŸ”¥ **Loop de Feedback** - Aprende com decisÃµes clÃ­nicas reais
- ğŸ”¥ **Workflow de AprovaÃ§Ã£o** - Preview, diff visual, rollback automÃ¡tico

**Resultado:** ReduÃ§Ã£o de 90% no tempo de implementaÃ§Ã£o de melhorias (de dias para minutos).

---

## ğŸš€ InÃ­cio RÃ¡pido

### 1. Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

### 2. Configurar OpenRouter

Crie um arquivo `.env` na raiz do projeto:

```env
OPENROUTER_API_KEY=sk-or-v1-sua-chave-aqui
```

**Obter chave de API**: https://openrouter.ai/keys

### 3. Executar AnÃ¡lise

```bash
python run_qa_cli.py
```

Siga as instruÃ§Ãµes:
1. Selecione o arquivo JSON do protocolo em `models_json/`
2. Selecione o arquivo do playbook (opcional mas recomendado)
3. Escolha o modelo LLM
4. Visualize os resultados em `reports/`

---

## ğŸ—ï¸ Arquitetura

### Agent V2: Arquitetura Centrada em LLM (ProduÃ§Ã£o)

**PrincÃ­pios fundamentais**:
- **Zero lÃ³gica clÃ­nica no cÃ³digo** - toda inteligÃªncia clÃ­nica vem do LLM
- **Chamada Ãºnica ao LLM** - anÃ¡lise abrangente via super prompt
- **AgnÃ³stico a especialidades** - funciona identicamente para ORL, AVC, Pediatria, etc.
- **Foco em sugestÃµes de melhoria** - recomendaÃ§Ãµes acionÃ¡veis para aprimoramento do protocolo

**Pipeline de ExecuÃ§Ã£o**:
```
Playbook + Protocolo â†’ protocol_loader (carregamento bruto)
    â†“
prompt_builder (montagem do super prompt com cache)
    â†“
llm_client â†’ API OpenRouter (anÃ¡lise abrangente Ãºnica)
    â†“
output/validator (validaÃ§Ã£o de schema)
    â†“
pipeline.analyze() â†’ SaÃ­da JSON unificada
    â†“
CLI Report Generator â†’ reports/*.txt, reports/*.json
```

### Agent V3: Arquitetura de CorreÃ§Ã£o Automatizada (Roadmap)

**EvoluÃ§Ã£o transformacional** em 3 etapas:

```
ETAPA 1: PREPROCESSAMENTO INTELIGENTE
Playbook gigante â†’ ChunkingEngine â†’ Chunks semÃ¢nticos
    â†“
SynthesisEngine â†’ Playbook-Synth compactado (sÃ³ essencial)
    â†“
MemoryManager â†’ Contexto mantido entre chunks

ETAPA 2: ANÃLISE + CORREÃ‡ÃƒO
Protocolo JSON + Playbook-Synth â†’ LLM (anÃ¡lise)
    â†“
RelatÃ³rio de melhorias + Scores de impacto
    â†“
ImprovementApplicator â†’ Protocolo JSON corrigido (auto-apply)
    â†“
ConfidenceScoring â†’ Alta confianÃ§a = auto-apply | Baixa = preview

ETAPA 3: APROVAÃ‡ÃƒO + APRENDIZADO
Protocolo corrigido â†’ ApprovalWorkflow (diff visual)
    â†“
UsuÃ¡rio aprova/rejeita â†’ FeedbackCollector
    â†“
LearningEngine â†’ Fine-tuning contÃ­nuo baseado em decisÃµes reais
```

**Ganhos esperados v3:**
- ğŸ”¥ Tempo de implementaÃ§Ã£o: dias â†’ minutos (-90%)
- ğŸ”¥ Custo de tokens: -50-70% (chunking + cache)
- ğŸ”¥ PrecisÃ£o: 80% â†’ 95%+ (loop de feedback)
- ğŸ”¥ ROI quantificÃ¡vel: R$ economizados + eventos evitados

---

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente (.env)

```env
# ObrigatÃ³rio
OPENROUTER_API_KEY=sk-or-v1-sua-chave-aqui

# Opcional
LLM_MODEL=anthropic/claude-sonnet-4.5  # Modelo padrÃ£o v3
```

### Modelos Suportados

**Recomendados para v2/v3:**
- `anthropic/claude-sonnet-4.5` â­ (recomendado v3 - auto-apply)
- `anthropic/claude-sonnet-4-20250514` (alternativa)
- `google/gemini-2.5-flash-preview-09-2025` ğŸ”§ (v2 padrÃ£o)

**Outros modelos disponÃ­veis:**
- `anthropic/claude-3.5-haiku-20241022` (mais rÃ¡pido, mais barato)
- `google/gemini-2.5-flash`, `google/gemini-2.5-pro`
- `openai/gpt-5-mini`, `openai/gpt-4.1-mini`, `openai/gpt-4o-mini`
- `x-ai/grok-2-1212`

**Total**: 12+ modelos disponÃ­veis

---

## ğŸ“Š Formato de SaÃ­da

### V2 (Atual)

**RelatÃ³rio em Texto** (`reports/*.txt`):
- Resumo da estrutura do protocolo
- Resumo da extraÃ§Ã£o do playbook
- ValidaÃ§Ã£o clÃ­nica (cobertura, gaps)
- AnÃ¡lise de eficiÃªncia
- SugestÃµes de melhoria
- MÃ©tricas de qualidade

**RelatÃ³rio em JSON** (`reports/*.json`):
- Dados estruturados completos
- Todos os resultados da anÃ¡lise
- Metadados (timestamps, modelo usado, tempos de processamento)
- Contagens de entidades (sÃ­ndromes, exames, tratamentos)

### V3 (Futuro)

**AdiÃ§Ãµes ao output:**
- âœ… Protocolo JSON corrigido (`reports/*_fixed.json`)
- âœ… Diff visual de mudanÃ§as (`reports/*_diff.html`)
- âœ… Scores de impacto por sugestÃ£o (SeguranÃ§a 0-10, Economia R$, EsforÃ§o horas)
- âœ… ROI calculado de cada melhoria
- âœ… Rastreabilidade completa (qual fonte de evidÃªncia justifica cada mudanÃ§a)
- âœ… Logs de aprovaÃ§Ã£o/rejeiÃ§Ã£o (feedback loop)

---

## ğŸ”§ SoluÃ§Ã£o de Problemas

### "API key nÃ£o configurada"

**Causa**: `OPENROUTER_API_KEY` nÃ£o configurado

**SoluÃ§Ã£o**:
```bash
# Verifique se o .env existe
type .env  # Windows
cat .env   # Linux/Mac

# Ou crie manualmente
echo OPENROUTER_API_KEY=sk-or-v1-sua-chave > .env
```

### "Nenhum arquivo de protocolo encontrado"

**Causa**: Nenhum arquivo JSON em `models_json/`

**SoluÃ§Ã£o**: Adicione arquivos JSON de protocolos no diretÃ³rio `models_json/`

### "Playbook muito grande - context overflow"

**Causa (v2)**: Playbook >50 pÃ¡ginas excede janela de contexto

**SoluÃ§Ã£o temporÃ¡ria**: Reduza playbook manualmente ou divida em seÃ§Ãµes

**SoluÃ§Ã£o definitiva (v3)**: ChunkingEngine processarÃ¡ playbooks gigantes automaticamente

---

## ğŸ“š DocumentaÃ§Ã£o

**DocumentaÃ§Ã£o Oficial** (consolidada em 3 arquivos principais):

- **Este arquivo** (`README.md`) - VisÃ£o geral e uso
- **`roadmap.md`** - Roadmap completo v2 â†’ v3
- **`dev_history.md`** - HistÃ³rico de desenvolvimento (log append-only)

**Recursos Adicionais**:

- `REVIEW_CLAUDE.txt` - EspecificaÃ§Ã£o completa do Agent V2
- `src/agent_v2/` - CÃ³digo-fonte do Agent V2

---

## ğŸ¯ PrincÃ­pios-Chave

### PrincÃ­pios de Design do Agent V2/V3

1. **Zero LÃ³gica ClÃ­nica no CÃ³digo**
   - Todas as decisÃµes clÃ­nicas vÃªm do LLM
   - Sem regras hardcoded, regex ou heurÃ­sticas
   - CÃ³digo Ã© pura orquestraÃ§Ã£o

2. **Chamada Ãšnica ao LLM** (v2) â†’ **Chunking Inteligente** (v3)
   - v2: Um super prompt abrangente
   - v3: Processamento incremental com sÃ­ntese

3. **AgnÃ³stico a Especialidades**
   - Mesmo caminho de cÃ³digo para todas as especialidades mÃ©dicas
   - Sem lÃ³gica `if especialidade == "ORL"`
   - Conhecimento especÃ­fico de especialidade nos playbooks, nÃ£o no cÃ³digo

4. **De Passivo para Ativo** (v3)
   - v2: Identifica problemas
   - v3: Identifica + Corrige automaticamente

5. **Fail-Fast com SeguranÃ§a**
   - Erros sÃ£o registrados e propagados imediatamente
   - Auto-apply somente com alta confianÃ§a (>90%)
   - AprovaÃ§Ã£o humana obrigatÃ³ria para mudanÃ§as crÃ­ticas

6. **Aprendizado ContÃ­nuo** (v3)
   - Sistema aprende com decisÃµes clÃ­nicas reais
   - Fine-tuning baseado em feedback
   - PrecisÃ£o melhora ao longo do tempo

---

## ğŸ“ˆ Performance

### Agent V2 (Atual)
- **LatÃªncia p95**: â‰¤ 60 segundos
- **Custo por anÃ¡lise**: ~R$ 0,25-0,50 (depende do modelo)
- **Taxa de sucesso**: â‰¥ 95%
- **Cache de prompts**: Reduz atÃ© 90% do custo em anÃ¡lises repetidas

### Agent V3 (Expectativa)
- **LatÃªncia p95**: â‰¤ 90 segundos (chunking + auto-apply)
- **Custo por anÃ¡lise**: ~R$ 0,15-0,30 (-50% via chunking otimizado)
- **Taxa de sucesso**: â‰¥ 98%
- **Tempo de implementaÃ§Ã£o de melhorias**: Dias â†’ Minutos (-90%)
- **PrecisÃ£o de sugestÃµes**: 80% â†’ 95%+ (apÃ³s 3-6 meses de feedback)

---

## ğŸ”— Links Ãšteis

- **OpenRouter**: https://openrouter.ai
- **Chaves de API**: https://openrouter.ai/keys
- **CatÃ¡logo de Modelos**: https://openrouter.ai/models
- **Anthropic Claude**: https://www.anthropic.com/claude

---

## ğŸ“ Uso ProgramÃ¡tico

### V2 (Atual)

```python
from agent_v2.pipeline import analyze

# AnÃ¡lise completa
resultado = analyze(
    protocol_path="models_json/protocolo.json",
    playbook_path="models_json/playbook.md",
    model="anthropic/claude-sonnet-4.5"
)

# Resultado contÃ©m:
# - protocol_analysis: anÃ¡lise estrutural e extraÃ§Ã£o clÃ­nica
# - improvement_suggestions: sugestÃµes de melhoria priorizadas
# - metadata: informaÃ§Ãµes sobre processamento, modelo, qualidade
```

### V3 (Futuro)

```python
from agent_v3.pipeline import analyze_and_fix

# AnÃ¡lise + CorreÃ§Ã£o automatizada
resultado = analyze_and_fix(
    protocol_path="models_json/protocolo.json",
    playbook_path="models_json/playbook_gigante.pdf",  # Suporta playbooks massivos
    model="anthropic/claude-sonnet-4.5",
    auto_apply=True,  # Aplica correÃ§Ãµes automaticamente
    confidence_threshold=0.90  # SÃ³ auto-apply se confianÃ§a >90%
)

# Resultado contÃ©m:
# - protocol_analysis: anÃ¡lise estrutural
# - improvement_suggestions: sugestÃµes ranqueadas por impacto
# - fixed_protocol: protocolo JSON corrigido
# - changes_diff: diff visual de mudanÃ§as
# - impact_scores: scores de seguranÃ§a, economia, esforÃ§o
# - metadata: custo, tempo, confianÃ§a de cada mudanÃ§a
```

---

## ğŸ¯ PrÃ³ximos Passos

### Para UsuÃ¡rios (v2)
1. âœ… Use v2 em produÃ§Ã£o para validaÃ§Ã£o de protocolos
2. âœ… Colete feedback sobre qualidade das sugestÃµes
3. â³ Aguarde v3 para correÃ§Ã£o automatizada

### Para Desenvolvedores
1. ğŸ”¥ **Validar hipÃ³tese de auto-apply** (experimento 1 semana)
2. ğŸ”¥ **Implementar ChunkingEngine** (MVP 2 semanas)
3. ğŸ”¥ **Implementar ImprovementApplicator** (2-4 meses)
4. â³ Ver roadmap completo em `roadmap.md`

---

**Para o roadmap detalhado v2 â†’ v3, veja [`roadmap.md`](roadmap.md)**  
**Para o histÃ³rico de desenvolvimento, veja [`dev_history.md`](dev_history.md)**